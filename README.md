# self_attention
Superficial research on Self-attention models to understand the mechanisms behind impressive transformers like GPT.
